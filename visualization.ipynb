{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "Using gpu device 0: GeForce GTX TITAN X (CNMeM is disabled, cuDNN 5005)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"/media/HDD_2TB/marc/Video_Description/egocentric-video-description\")\n",
    "sys.path.append(\"/media/HDD_2TB/marc/multimodal_keras_wrapper\")\n",
    "\n",
    "from viddesc_model import VideoDesc_Model\n",
    "from data_engine.prepare_data import build_dataset\n",
    "from config import load_parameters\n",
    "\n",
    "from keras_wrapper.cnn_model import loadModel, saveModel\n",
    "from keras_wrapper.dataset import loadDataset\n",
    "from keras_wrapper.extra.evaluation import *\n",
    "from keras_wrapper.extra.callbacks import EarlyStopping\n",
    "\n",
    "# Plot libraries\n",
    "from matplotlib.patches import Rectangle\n",
    "import matplotlib as mpl\n",
    "mpl.use('Agg') # run matplotlib without X server (GUI)\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image as pilimage\n",
    "from scipy import ndimage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "description\n",
      "prev_description\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load basic dataset\n",
    "params = load_parameters()\n",
    "params['REBUILD_DATASET'] = False\n",
    "dataset = build_dataset(params)\n",
    "params['OUTPUT_VOCABULARY_SIZE'] = dataset.vocabulary_len[params['OUTPUTS_IDS_DATASET'][0]]\n",
    "\n",
    "params['RELOAD'] = 2\n",
    "params['STORE_PATH'] = 'trained_models/EDUB-SegDesc_features_ArcticVideoCaptionWithInit_txtemb_420_imgemb__lstmenc_600_lstm_484_deepout_maxout_Adam'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lifelogging/code/keras_marc/keras/layers/core.py:656: UserWarning: `output_shape` argument not specified for layer lambda_1 and cannot be automatically inferred with the Theano backend. Defaulting to output shape `(None, None, 301)` (same as input shape). If the expected output shape is different, specify it via the `output_shape` argument.\n",
      "  .format(self.name, input_shape))\n"
     ]
    }
   ],
   "source": [
    "# Load initial model\n",
    "model = loadModel('/media/HDD_2TB/marc/Video_Description/egocentric-video-description/'+params['STORE_PATH'], \n",
    "                      params['RELOAD'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------------------------------------\n",
      "\t\tVideoDesc_Model instance\n",
      "-----------------------------------------------------------------------------------\n",
      "_model_type: TemporallyLinkedVideoDescriptionAtt\n",
      "name: EDUB-SegDesc_features-linked_TemporallyLinkedVideoDescriptionAtt_txtemb_301_imgemb__lstmenc_717_lstm_484_deepout_maxout_Adam\n",
      "model_path: trained_models/EDUB-SegDesc_features_ArcticVideoCaptionWithInit_txtemb_420_imgemb__lstmenc_600_lstm_484_deepout_maxout_Adam\n",
      "verbose: 1\n",
      "\n",
      "MODEL params:\n",
      "{'SAMPLE_ON_SETS': ['train', 'val'], 'MAX_OUTPUT_TEXT_LEN': 30, 'SAMPLING_SAVE_MODE': 'list', 'TRG_LAN': 'en', 'SAMPLING': 'max_likelihood', 'SAMPLE_EACH_UPDATES': 1, 'CLIP_C': 1.0, 'TRG_PRETRAINED_VECTORS_TRAINABLE': True, 'USE_PRELU': False, 'ENCODER_HIDDEN_SIZE': 717, 'REBUILD_DATASET': False, 'BATCH_NORMALIZATION_MODE': 1, 'OPTIMIZER': 'Adam', 'EVAL_EACH_EPOCHS': False, 'EPOCHS_FOR_SAVE': 1, 'USE_BATCH_NORMALIZATION': True, 'BATCH_SIZE': 64, 'MODEL_NAME': 'EDUB-SegDesc_features-linked_TemporallyLinkedVideoDescriptionAtt_txtemb_301_imgemb__lstmenc_717_lstm_484_deepout_maxout_Adam', 'METRICS': ['coco'], 'TRAIN_ON_TRAINVAL': False, 'N_SAMPLES': 5, 'RECURRENT_DROPOUT_P': 0.5, 'PRE_TRAINED_MODEL': 'MSVD_best_model', 'MIN_OCCURRENCES_VOCAB': 0, 'OUTPUTS_IDS_DATASET': ['description'], 'INIT_LAYERS': ['tanh'], 'EARLY_STOP': True, 'DATA_AUGMENTATION': False, 'RECURRENT_WEIGHT_DECAY': 0.0, 'START_SAMPLING_ON_EPOCH': 0, 'PARALLEL_LOADERS': 8, 'SAMPLE_WEIGHTS': True, 'FRAMES_COUNTS_FILES': {'test': 'Annotations/%s/test_feat_counts.txt', 'train': 'Annotations/%s/train_feat_counts.txt', 'val': 'Annotations/%s/val_feat_counts.txt'}, 'EVAL_EACH': 50, 'EXTRA_NAME': '', 'LOSS': 'categorical_crossentropy', 'WRITE_VALID_SAMPLES': True, 'INPUTS_IDS_MODEL': ['video', 'state_below', 'prev_description', 'link_index'], 'PRE_TRAINED_DATASET_NAME': 'MSVD_features', 'NUM_FRAMES': 26, 'LR_GAMMA': 0.8, 'NOISE_AMOUNT': 0.01, 'STOP_METRIC': 'Bleu_4', 'FEATURE_NAMES': ['ImageNet'], 'N_LAYERS_ENCODER': 1, 'INPUTS_IDS_DATASET': ['video', 'state_below', 'prev_description', 'link_index'], 'BIDIRECTIONAL_ENCODER': True, 'MAX_OUTPUT_TEXT_LEN_TEST': 120, 'FORCE_RELOAD_VOCABULARY': False, 'layer': ('maxout', 150), 'TOKENIZATION_METHOD': 'tokenize_icann', 'OUTPUT_VOCABULARY_SIZE': 832, 'START_EVAL_ON_EPOCH': 1, 'BEAM_SEARCH': True, 'TARGET_TEXT_EMBEDDING_SIZE': 301, 'DECODER_HIDDEN_SIZE': 484, 'LAYERS_MAPPING': {'initial_memory': 'initial_memory', 'logit_lstm': 'logit_lstm', 'target_word_embedding': 'target_word_embedding', 'logit_ctx': 'logit_ctx', 'attlstmcond_1': 'decoder_AttLSTMCond2Inputs', 'initial_state': 'initial_state', 'bidirectional_encoder': 'bidirectional_encoder_LSTM', 'description': 'description'}, 'MODEL_TYPE': 'TemporallyLinkedVideoDescriptionAtt', 'TRG_PRETRAINED_VECTORS': None, 'MAX_EPOCH': 50, 'EVAL_ON_SETS_KERAS': [], 'LINK_SAMPLE_FILES': {'test': 'Annotations/test_link_samples.txt', 'train': 'Annotations/train_link_samples.txt', 'val': 'Annotations/val_link_samples.txt'}, 'LOAD_WEIGHTS_ONLY': True, 'NORMALIZE_SAMPLING': True, 'VOCABULARIES_MAPPING': {'description': 'prev_description'}, 'PAD_ON_BATCH': True, 'DESCRIPTION_COUNTS_FILES': {'test': 'Annotations/test_descriptions_counts.npy', 'train': 'Annotations/train_descriptions_counts.npy', 'val': 'Annotations/val_descriptions_counts.npy'}, 'RNN_TYPE': 'LSTM', 'BEAM_SIZE': 10, 'DESCRIPTION_FILES': {'test': 'Annotations/test_descriptions.txt', 'train': 'Annotations/train_descriptions.txt', 'val': 'Annotations/val_descriptions.txt'}, 'LR': 0.001, 'MODE': 'training', 'OPTIMIZED_SEARCH': True, 'CLASSIFIER_ACTIVATION': 'softmax', 'FILL': 'end', 'FRAMES_LIST_FILES': {'test': 'Annotations/%s/test_feat_list.txt', 'train': 'Annotations/%s/train_feat_list.txt', 'val': 'Annotations/%s/val_feat_list.txt'}, 'ALPHA_FACTOR': 0.6, 'BEAM_SEARCH_COND_INPUT': 1, 'TEMPERATURE': 1, 'STORE_PATH': 'trained_models/EDUB-SegDesc_features_ArcticVideoCaptionWithInit_txtemb_420_imgemb__lstmenc_600_lstm_484_deepout_maxout_Adam', 'USE_RECURRENT_DROPOUT': False, 'IMG_EMBEDDING_LAYERS': [], 'DATASET_STORE_PATH': 'datasets/', 'DROPOUT_P': 0.5, 'PRE_TRAINED_MODEL_STORE_PATH': 'trained_models/MSVD_best_model/', 'DATA_ROOT_PATH': '/media/HDD_3TB/DATASETS/EDUB-SegDesc/', 'HOMOGENEOUS_BATCHES': False, 'LR_DECAY': 1, 'DATASET_NAME': 'EDUB-SegDesc_features-linked', 'INPUT_DATA_TYPE': 'video-features', 'USE_DROPOUT': False, 'WEIGHT_DECAY': 0.0001, 'VERBOSE': 1, 'PATIENCE': 20, 'BIDIRECTIONAL_DEEP_ENCODER': True, 'OUTPUTS_IDS_MODEL': ['description'], 'USE_NOISE': True, 'DEEP_OUTPUT_LAYERS': [('maxout', 150)], 'RELOAD': 2, 'EVAL_ON_SETS': ['val', 'test'], 'IMG_FEAT_SIZE': 1024, 'USE_L2': False}\n",
      "-----------------------------------------------------------------------------------\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "video (InputLayer)               (None, None, 1024)    0                                            \n",
      "____________________________________________________________________________________________________\n",
      "bidirectional_encoder_LSTM (Bidi (None, None, 1434)    9992112     video[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "merge_1 (Merge)                  (None, None, 2458)    0           video[0][0]                      \n",
      "                                                                   bidirectional_encoder_LSTM[0][0] \n",
      "____________________________________________________________________________________________________\n",
      "input_video_gaussian_noise (Gaus (None, None, 2458)    0           merge_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "input_video_batch_normalization  (None, None, 2458)    9832        input_video_gaussian_noise[0][0] \n",
      "____________________________________________________________________________________________________\n",
      "prev_description (InputLayer)    (None, None)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "target_word_embedding (Embedding (None, None, 301)     250432      state_below[0][0]                \n",
      "                                                                   prev_description[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "state_below (InputLayer)         (None, None)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "lambda_mean (Lambda)             (None, 2458)          0           input_video_batch_normalization[0\n",
      "____________________________________________________________________________________________________\n",
      "encoder_prev_descLSTM (LSTM)     (None, None, 484)     1521696     target_word_embedding[1][0]      \n",
      "____________________________________________________________________________________________________\n",
      "initial_state (Dense)            (None, 484)           1190156     lambda_mean[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "initial_memory (Dense)           (None, 484)           1190156     lambda_mean[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "target_word_embedding_gaussian_n (None, None, 301)     0           target_word_embedding[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "prev_desc_enc_gaussian_noise (Ga (None, None, 484)     0           encoder_prev_descLSTM[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "initial_state_gaussian_noise (Ga (None, 484)           0           initial_state[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "initial_memory_gaussian_noise (G (None, 484)           0           initial_memory[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "target_word_embedding_batch_norm (None, None, 301)     1204        target_word_embedding_gaussian_no\n",
      "____________________________________________________________________________________________________\n",
      "prev_desc_enc_batch_normalizatio (None, None, 484)     1936        prev_desc_enc_gaussian_noise[0][0\n",
      "____________________________________________________________________________________________________\n",
      "initial_state_batch_normalizatio (None, 484)           1936        initial_state_gaussian_noise[0][0\n",
      "____________________________________________________________________________________________________\n",
      "initial_memory_batch_normalizati (None, 484)           1936        initial_memory_gaussian_noise[0][\n",
      "____________________________________________________________________________________________________\n",
      "decoder_AttLSTMCond2Inputs (AttL [(None, None, 484), ( 14923242    target_word_embedding_batch_norma\n",
      "                                                                   input_video_batch_normalization[0\n",
      "                                                                   prev_desc_enc_batch_normalization\n",
      "                                                                   initial_state_batch_normalization\n",
      "                                                                   initial_memory_batch_normalizatio\n",
      "____________________________________________________________________________________________________\n",
      "proj_h0_gaussian_noise (Gaussian (None, None, 484)     0           decoder_AttLSTMCond2Inputs[0][0] \n",
      "____________________________________________________________________________________________________\n",
      "proj_h0_batch_normalization (Bat (None, None, 484)     1936        proj_h0_gaussian_noise[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "logit_ctx (TimeDistributed)      multiple              740159      decoder_AttLSTMCond2Inputs[0][1] \n",
      "____________________________________________________________________________________________________\n",
      "logit_prev (TimeDistributed)     multiple              145985      decoder_AttLSTMCond2Inputs[0][3] \n",
      "____________________________________________________________________________________________________\n",
      "logit_lstm (TimeDistributed)     multiple              145985      proj_h0_batch_normalization[0][0]\n",
      "____________________________________________________________________________________________________\n",
      "permutegeneral_1 (PermuteGeneral (None, None, 301)     0           logit_ctx[0][0]                  \n",
      "                                                                   logit_prev[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "logit_emb (TimeDistributed)      multiple              90902       target_word_embedding_batch_norma\n",
      "____________________________________________________________________________________________________\n",
      "out_layer_mlp_gaussian_noise (Ga (None, None, 301)     0           logit_lstm[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "out_layer_ctx_gaussian_noise (Ga (None, None, 301)     0           permutegeneral_1[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "out_layer_emb_gaussian_noise (Ga (None, None, 301)     0           logit_emb[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "out_layer_prev_gaussian_noise (G (None, None, 301)     0           permutegeneral_1[1][0]           \n",
      "____________________________________________________________________________________________________\n",
      "out_layer_mlp_batch_normalizatio (None, None, 301)     1204        out_layer_mlp_gaussian_noise[0][0\n",
      "____________________________________________________________________________________________________\n",
      "out_layer_ctx_batch_normalizatio (None, None, 301)     1204        out_layer_ctx_gaussian_noise[0][0\n",
      "____________________________________________________________________________________________________\n",
      "out_layer_emb_batch_normalizatio (None, None, 301)     1204        out_layer_emb_gaussian_noise[0][0\n",
      "____________________________________________________________________________________________________\n",
      "out_layer_prev_batch_normalizati (None, None, 301)     1204        out_layer_prev_gaussian_noise[0][\n",
      "____________________________________________________________________________________________________\n",
      "additional_input (Merge)         (None, None, 301)     0           out_layer_mlp_batch_normalization\n",
      "                                                                   out_layer_ctx_batch_normalization\n",
      "                                                                   out_layer_emb_batch_normalization\n",
      "                                                                   out_layer_prev_batch_normalizatio\n",
      "____________________________________________________________________________________________________\n",
      "activation_1 (Activation)        (None, None, 301)     0           additional_input[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "maxout_0 (TimeDistributed)       multiple              181200      activation_1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "out_layermaxout_gaussian_noise ( (None, None, 150)     0           maxout_0[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "out_layermaxout_batch_normalizat (None, None, 150)     600         out_layermaxout_gaussian_noise[0]\n",
      "____________________________________________________________________________________________________\n",
      "description (TimeDistributed)    multiple              125632      out_layermaxout_batch_normalizati\n",
      "====================================================================================================\n",
      "Total params: 30,521,853\n",
      "Trainable params: 30,509,755\n",
      "Non-trainable params: 12,098\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "video_model = VideoDesc_Model(params,\n",
    "                                      type=params['MODEL_TYPE'],\n",
    "                                      verbose=params['VERBOSE'],\n",
    "                                      model_name=params['MODEL_NAME'],\n",
    "                                      vocabularies=dataset.vocabulary,\n",
    "                                      store_path=params['STORE_PATH'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lifelogging/code/keras_marc/keras/layers/core.py:656: UserWarning: `output_shape` argument not specified for layer lambda_1 and cannot be automatically inferred with the Theano backend. Defaulting to output shape `(None, None, 301)` (same as input shape). If the expected output shape is different, specify it via the `output_shape` argument.\n",
      "  .format(self.name, input_shape))\n"
     ]
    }
   ],
   "source": [
    "old_model = loadModel(params['PRE_TRAINED_MODEL_STORE_PATH'], params['RELOAD'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print old_model.model_next\n",
    "print old_model.model_init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "old_names = [layer.name for layer in old_model.model.layers]\n",
    "new_names = [layer.name for layer in video_model.model.layers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'video', u'bidirectional_encoder', u'merge_1', u'lambda_mean', u'dropout_1', u'state_below', u'initial_state', u'initial_memory', u'target_word_embedding', u'dropout_2', u'dropout_3', u'attlstmcond_1', u'dropout_4', u'logit_ctx', u'logit_lstm', u'lambda_1', u'additional_input', u'activation_1', u'dropout_5', u'description']\n",
      "\n",
      "['video', 'bidirectional_encoder_LSTM', 'merge_2', 'input_video_gaussian_noise', 'input_video_batch_normalization', 'prev_description', 'target_word_embedding', 'state_below', 'lambda_mean', 'encoder_prev_descLSTM', 'initial_state', 'initial_memory', 'target_word_embedding_gaussian_noise', 'prev_desc_enc_gaussian_noise', 'initial_state_gaussian_noise', 'initial_memory_gaussian_noise', 'target_word_embedding_batch_normalization', 'prev_desc_enc_batch_normalization', 'initial_state_batch_normalization', 'initial_memory_batch_normalization', 'decoder_AttLSTMCond2Inputs', 'proj_h0_gaussian_noise', 'proj_h0_batch_normalization', 'logit_ctx', 'logit_prev', 'logit_lstm', 'permutegeneral_2', 'logit_emb', 'out_layer_mlp_gaussian_noise', 'out_layer_ctx_gaussian_noise', 'out_layer_emb_gaussian_noise', 'out_layer_prev_gaussian_noise', 'out_layer_mlp_batch_normalization', 'out_layer_ctx_batch_normalization', 'out_layer_emb_batch_normalization', 'out_layer_prev_batch_normalization', 'additional_input', 'activation_2', 'maxout_0', 'out_layermaxout_gaussian_noise', 'out_layermaxout_batch_normalization', 'description']\n"
     ]
    }
   ],
   "source": [
    "print old_names\n",
    "print\n",
    "print new_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "old_layer_dict = dict([(layer.name, layer) for layer in old_model.model.layers])\n",
    "new_layer_dict = dict([(layer.name, layer) for layer in video_model.model.layers])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1024, 2868)\n",
      "(717, 2868)\n",
      "(2868,)\n",
      "(1024, 2868)\n",
      "(717, 2868)\n",
      "(2868,)\n",
      "\n",
      "(1024, 2868)\n",
      "(717, 2868)\n",
      "(2868,)\n",
      "(1024, 2868)\n",
      "(717, 2868)\n",
      "(2868,)\n"
     ]
    }
   ],
   "source": [
    "old_weights = old_layer_dict['bidirectional_encoder'].get_weights()\n",
    "for w in old_weights:\n",
    "    print w.shape\n",
    "print\n",
    "new_weights = new_layer_dict['bidirectional_encoder_LSTM'].get_weights()\n",
    "for w in new_weights:\n",
    "    print w.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2458, 484)\n",
      "(484,)\n",
      "\n",
      "(2458, 484)\n",
      "(484,)\n"
     ]
    }
   ],
   "source": [
    "old_weights = old_layer_dict['initial_state'].get_weights()\n",
    "for w in old_weights:\n",
    "    print w.shape\n",
    "print\n",
    "new_weights = new_layer_dict['initial_state'].get_weights()\n",
    "for w in new_weights:\n",
    "    print w.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13578, 301)\n",
      "\n",
      "(832, 301)\n"
     ]
    }
   ],
   "source": [
    "old_weights = old_layer_dict['target_word_embedding'].get_weights()\n",
    "for w in old_weights:\n",
    "    print w.shape\n",
    "print\n",
    "new_weights = new_layer_dict['target_word_embedding'].get_weights()\n",
    "for w in new_weights:\n",
    "    print w.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2458,)\n",
      "(484, 2458)\n",
      "(2458, 2458)\n",
      "(2458,)\n",
      "(26,)\n",
      "(301, 1936)\n",
      "(2458, 1936)\n",
      "(484, 1936)\n",
      "(1936,)\n",
      "\n",
      "(2458,)\n",
      "(484, 2458)\n",
      "(2458, 2458)\n",
      "(2458,)\n",
      "()\n",
      "(2458, 1936)\n",
      "(484, 1936)\n",
      "(484, 1936)\n",
      "(301, 1936)\n",
      "(1936,)\n",
      "(484,)\n",
      "(484, 484)\n",
      "(484, 484)\n",
      "(484,)\n",
      "()\n"
     ]
    }
   ],
   "source": [
    "old_weights = old_layer_dict['attlstmcond_1'].get_weights()\n",
    "for w in old_weights:\n",
    "    print w.shape\n",
    "print\n",
    "new_weights = new_layer_dict['decoder_AttLSTMCond2Inputs'].get_weights()\n",
    "for w in new_weights:\n",
    "    print w.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2458, 301)\n",
      "(301,)\n",
      "\n",
      "(2458, 301)\n",
      "(301,)\n"
     ]
    }
   ],
   "source": [
    "old_weights = old_layer_dict['logit_ctx'].get_weights()\n",
    "for w in old_weights:\n",
    "    print w.shape\n",
    "print\n",
    "new_weights = new_layer_dict['logit_ctx'].get_weights()\n",
    "for w in new_weights:\n",
    "    print w.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(484, 301)\n",
      "(301,)\n",
      "\n",
      "(484, 301)\n",
      "(301,)\n"
     ]
    }
   ],
   "source": [
    "old_weights = old_layer_dict['logit_lstm'].get_weights()\n",
    "for w in old_weights:\n",
    "    print w.shape\n",
    "print\n",
    "new_weights = new_layer_dict['logit_lstm'].get_weights()\n",
    "for w in new_weights:\n",
    "    print w.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(301, 13578)\n",
      "(13578,)\n",
      "\n",
      "(150, 832)\n",
      "(832,)\n"
     ]
    }
   ],
   "source": [
    "old_weights = old_layer_dict['description'].get_weights()\n",
    "for w in old_weights:\n",
    "    print w.shape\n",
    "print\n",
    "new_weights = new_layer_dict['description'].get_weights()\n",
    "for w in new_weights:\n",
    "    print w.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras_wrapper.cnn_model import transferWeights as tw\n",
    "\n",
    "video_model = tw(old_model, video_model, params['LAYERS_MAPPING'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'video_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-c057fb94bb29>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mprint\u001b[0m \u001b[0mvideo_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvocabularies\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvideo_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvocabularies\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'prev_description'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'idx2words'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'video_model' is not defined"
     ]
    }
   ],
   "source": [
    "print video_model.vocabularies.keys()\n",
    "len(video_model.vocabularies['prev_description']['idx2words'].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13578"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset.vocabulary['prev_description']['idx2words'].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['prev_description', 'state_below', 'description']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.vocabulary.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13578"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset.vocabulary['description']['idx2words'].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataset_pretrained = loadDataset(params['DATASET_STORE_PATH']+'Dataset_'+params['PRE_TRAINED_DATASET_NAME']+'.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'prev_description': 13578, 'state_below': 13578, 'description': 13578}\n",
      "{'description': 13578}\n"
     ]
    }
   ],
   "source": [
    "print dataset.vocabulary_len\n",
    "print dataset_pretrained.vocabulary_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset.vocabulary['description'] = copy.deepcopy(dataset_pretrained.vocabulary['description'])\n",
    "dataset.vocabulary_len['description'] = copy.deepcopy(dataset_pretrained.vocabulary_len['description'])\n",
    "\n",
    "dataset.vocabulary['prev_description'] = copy.deepcopy(dataset_pretrained.vocabulary['description'])\n",
    "dataset.vocabulary_len['prev_description'] = copy.deepcopy(dataset_pretrained.vocabulary_len['description'])\n",
    "\n",
    "dataset.vocabulary['state_below'] = copy.deepcopy(dataset_pretrained.vocabulary['description'])\n",
    "dataset.vocabulary_len['state_below'] = copy.deepcopy(dataset_pretrained.vocabulary_len['description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "description\n",
      "prev_description\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for id_old, id_new in params['VOCABULARIES_MAPPING'].iteritems():\n",
    "            print id_old\n",
    "            print id_new\n",
    "            print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'description': 'prev_description'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params['VOCABULARIES_MAPPING']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
